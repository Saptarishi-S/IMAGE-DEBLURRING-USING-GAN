{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "qWGCCfEhSMFQ",
        "outputId": "ff00152c-ce7e-45ed-fb8d-618d2d57e4cc"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'generator_model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2e84c24ba5a9>\u001b[0m in \u001b[0;36m<cell line: 52>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Initialize models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0md_on_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_containing_discriminator_multiple_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'generator_model' is not defined"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, Activation, BatchNormalization, LeakyReLU, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "def discriminator_model(input_shape=(256, 256, 3)):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv2D(filters=64, kernel_size=(4, 4), strides=(2, 2), padding='same')(inputs)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Conv2D(filters=128, kernel_size=(4, 4), strides=(2, 2), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Conv2D(filters=256, kernel_size=(4, 4), strides=(2, 2), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Conv2D(filters=512, kernel_size=(4, 4), strides=(2, 2), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    # Flatten and output layer\n",
        "    x = Flatten()(x)\n",
        "    outputs = Dense(1)(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs, name='Discriminator')\n",
        "    return model\n",
        "\n",
        "# Assuming load_images and generator_model functions are already defined\n",
        "\n",
        "# Define generator_containing_discriminator_multiple_outputs\n",
        "def generator_containing_discriminator_multiple_outputs(generator, discriminator):\n",
        "    inputs = Input(shape=(256, 256, 3))\n",
        "    generated_images = generator(inputs)\n",
        "    discriminator.trainable = False\n",
        "    outputs = discriminator(generated_images)\n",
        "    return Model(inputs, [generated_images, outputs])\n",
        "\n",
        "#change generator model variable as required\n",
        "g = generator_model()\n",
        "d = discriminator_model()\n",
        "d_on_g = generator_containing_discriminator_multiple_outputs(g, d)\n",
        "\n",
        "g_opt = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "d_opt = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "d_on_g_opt = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "\n",
        "d.trainable = True\n",
        "d.compile(optimizer=d_opt, loss=wasserstein_loss)\n",
        "d.trainable = False\n",
        "loss = [perceptual_loss, wasserstein_loss]\n",
        "loss_weights = [100, 1]\n",
        "d_on_g.compile(optimizer=d_on_g_opt, loss=loss, loss_weights=loss_weights)\n",
        "d.trainable = True\n",
        "\n",
        "\n",
        "epoch_num = 100\n",
        "batch_size = 16\n",
        "critic_updates = 5\n",
        "\n",
        "for epoch in range(epoch_num):\n",
        "    print('epoch: {}/{}'.format(epoch, epoch_num))\n",
        "    print('batches: {}'.format(x_train.shape[0] / batch_size))\n",
        "\n",
        "    permutated_indexes = np.random.permutation(x_train.shape[0])\n",
        "\n",
        "    for index in range(int(x_train.shape[0] / batch_size)):\n",
        "        batch_indexes = permutated_indexes[index*batch_size:(index+1)*batch_size]\n",
        "        image_blur_batch = x_train[batch_indexes]\n",
        "        image_full_batch = y_train[batch_indexes]\n",
        "\n",
        "        generated_images = g.predict(x=image_blur_batch, batch_size=batch_size)\n",
        "\n",
        "        for _ in range(critic_updates):\n",
        "            d_loss_real = d.train_on_batch(image_full_batch, np.ones((batch_size, 1)))\n",
        "            d_loss_fake = d.train_on_batch(generated_images, -np.ones((batch_size, 1)))\n",
        "            d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
        "\n",
        "        d.trainable = False\n",
        "        d_on_g_loss = d_on_g.train_on_batch(image_blur_batch, [image_full_batch, np.ones((batch_size, 1))])\n",
        "        d.trainable = True\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
