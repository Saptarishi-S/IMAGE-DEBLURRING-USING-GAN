{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRkt328z4Jap0Fr75u2HH5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armaanranjan/IMAGE-DEBLURRING-USING-GAN/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4YzvC_VgvXZ"
      },
      "outputs": [],
      "source": [
        "import keras.backend as K\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model\n",
        "\n",
        "image_shape = (256, 256, 3)\n",
        "\n",
        "def perceptual_loss(y_true, y_pred):\n",
        "    vgg = VGG16(include_top=False, weights='imagenet', input_shape=image_shape)\n",
        "    loss_model = Model(inputs=vgg.input, outputs=vgg.get_layer('block3_conv3').output)\n",
        "    loss_model.trainable = False\n",
        "    return K.mean(K.square(loss_model(y_true) - loss_model(y_pred)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def wasserstein_loss(y_true, y_pred):\n",
        "    return K.mean(y_true*y_pred)"
      ],
      "metadata": {
        "id": "Rf-xWrO6g8f8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_images('./images/train', n_images)\n",
        "y_train, x_train = data['B'], data['A']\n",
        "\n",
        "# Initialize models\n",
        "g = generator_model()\n",
        "d = discriminator_model()\n",
        "d_on_g = generator_containing_discriminator_multiple_outputs(g, d)\n",
        "\n",
        "# Initialize optimizers\n",
        "g_opt = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "d_opt = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "d_on_g_opt = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "\n",
        "# Compile models\n",
        "d.trainable = True\n",
        "d.compile(optimizer=d_opt, loss=wasserstein_loss)\n",
        "d.trainable = False\n",
        "loss = [perceptual_loss, wasserstein_loss]\n",
        "loss_weights = [100, 1]\n",
        "d_on_g.compile(optimizer=d_on_g_opt, loss=loss, loss_weights=loss_weights)\n",
        "d.trainable = True"
      ],
      "metadata": {
        "id": "_SJ4L5Sg7-n5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epoch_num):\n",
        "  print('epoch: {}/{}'.format(epoch, epoch_num))\n",
        "  print('batches: {}'.format(x_train.shape[0] / batch_size))\n",
        "\n",
        "  # Randomize images into batches\n",
        "  permutated_indexes = np.random.permutation(x_train.shape[0])\n",
        "\n",
        "  for index in range(int(x_train.shape[0] / batch_size)):\n",
        "      batch_indexes = permutated_indexes[index*batch_size:(index+1)*batch_size]\n",
        "      image_blur_batch = x_train[batch_indexes]\n",
        "      image_full_batch = y_train[batch_indexes]"
      ],
      "metadata": {
        "id": "xysu7MVF7-z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(epoch_num):\n",
        "  for index in range(batches):\n",
        "    # [Batch Preparation]\n",
        "\n",
        "    # Generate fake inputs\n",
        "    generated_images = g.predict(x=image_blur_batch, batch_size=batch_size)\n",
        "\n",
        "    # Train multiple times discriminator on real and fake inputs\n",
        "    for _ in range(critic_updates):\n",
        "        d_loss_real = d.train_on_batch(image_full_batch, output_true_batch)\n",
        "        d_loss_fake = d.train_on_batch(generated_images, output_false_batch)\n",
        "        d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
        "\n",
        "    d.trainable = False\n",
        "    # Train generator only on discriminator's decision and generated images\n",
        "    d_on_g_loss = d_on_g.train_on_batch(image_blur_batch, [image_full_batch, output_true_batch])\n",
        "\n",
        "    d.trainable = True"
      ],
      "metadata": {
        "id": "BqkvgKb78Qrb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}